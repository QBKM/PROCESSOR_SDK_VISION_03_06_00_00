<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>VLIB: VLIB_neuralNet_tile</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<table width=100%>
<tr>
  <td bgcolor="black" width="1"><a href="http://www.ti.com"><img border=0 src="tilogo.gif"></a></td>
  <td bgcolor="red"><img src="titagline.gif"></td>
</tr>
</table>
<!-- Generated by Doxygen 1.5.1-p1 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="modules.html"><span>Modules</span></a></li>
    <li><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
    <li><a href="files.html"><span>Files</span></a></li>
  </ul></div>
<h1>VLIB_neuralNet_tile</h1><hr><a name="_details"></a><h2>Detailed Description</h2>

<p>
<table border="0" cellpadding="0" cellspacing="0">
<tr><td></td></tr>
<tr><td colspan="2"><br><h2>Functions</h2></td></tr>
<tr><td class="memItemLeft" nowrap align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___v_l_i_b__neural_net__tile.html#g958d5b0b7dc115f5d3e375f53df7c483">VLIB_neuralNet_tile</a> (const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *pInNodes, const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *pWeight, const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *pBias, const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *pOutNodes, uint32_t mode, uint32_t shiftQ, uint32_t coeffQ, uint32_t dropOutQ)</td></tr>

</table>
<hr><h2>Function Documentation</h2>
<a class="anchor" name="g958d5b0b7dc115f5d3e375f53df7c483"></a><!-- doxytag: member="c66/VLIB_neuralNet_tile.h::VLIB_neuralNet_tile" ref="g958d5b0b7dc115f5d3e375f53df7c483" args="(const sBuffer_t *pInNodes, const sBuffer_t *pWeight, const sBuffer_t *pBias, const sBuffer_t *pOutNodes, uint32_t mode, uint32_t shiftQ, uint32_t coeffQ, uint32_t dropOutQ)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void VLIB_neuralNet_tile           </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *&nbsp;</td>
          <td class="paramname"> <em>pInNodes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *&nbsp;</td>
          <td class="paramname"> <em>pWeight</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *&nbsp;</td>
          <td class="paramname"> <em>pBias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structs_buffer__t.html">sBuffer_t</a> *&nbsp;</td>
          <td class="paramname"> <em>pOutNodes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&nbsp;</td>
          <td class="paramname"> <em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&nbsp;</td>
          <td class="paramname"> <em>shiftQ</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&nbsp;</td>
          <td class="paramname"> <em>coeffQ</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&nbsp;</td>
          <td class="paramname"> <em>dropOutQ</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td width="100%"></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>
<dl class="user" compact><dt><b>Description:</b></dt><dd>Produces L dotproduct values where each dotproduct is of multiplication and addition of N 16-bit inputs and N 16-bit weights. Each dotproduct value is added with a bias, rounded then shifted down to a signed 16-bit range. Depending on the user defined mode different activation functions such as ReLU, Sigmoid, Tanh are performed prior to storing in the output array. This process is repeated for M outputs. <br>
 <div class="fragment"><pre class="fragment">
    Data usage example (cols x rows):
                Input           : 1152 x 1          : N x M
                Weight          : 1152 x 92         : N x L
                Output          : 92 x 1            : L x M
    </pre></div> </dd></dl>
<dl class="user" compact><dt><b></b></dt><dd></dd></dl>
<dl compact><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>*pInNodes</em>&nbsp;</td><td>Pointer to N x M 16-bit input nodes </td></tr>
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>*pWeight</em>&nbsp;</td><td>Pointer to N x L 16-bit weights </td></tr>
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>*pBias</em>&nbsp;</td><td>Pointer to L 16-bit bias values </td></tr>
    <tr><td valign="top"><tt>[out]</tt>&nbsp;</td><td valign="top"><em>*pOutNodes</em>&nbsp;</td><td>Pointer to L x M 16-bit ouput nodes </td></tr>
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>mode</em>&nbsp;</td><td>To select activation type 1-ReLU, 2-Sigmoid, 3-TanH </td></tr>
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>shiftQ</em>&nbsp;</td><td>Shift value to adjust output range </td></tr>
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>coeffQ</em>&nbsp;</td><td>Shift value to adjust co-efficient range </td></tr>
    <tr><td valign="top"><tt>[in]</tt>&nbsp;</td><td valign="top"><em>dropOutQ</em>&nbsp;</td><td>Additional shift value to added with shiftQ to adjust output range when dropout method is used while training</td></tr>
  </table>
</dl>
<dl class="user" compact><dt><b>Assumptions:</b></dt><dd><ul>
<li>Input, output, weights and bias buffers are aligned to 8-byte boundary.</li><li>The number of cols in pWeight is assumed to be a multiple of 32.</li></ul>
</dd></dl>
<dl class="user" compact><dt><b>Implementation Notes:</b></dt><dd>The code is interruptible. <br>
 </dd></dl>

</div>
</div><p>
<hr size="1"><small>
Copyright  2018, Texas Instruments Incorporated</small>
</body>
</html>
